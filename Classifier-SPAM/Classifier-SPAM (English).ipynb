{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### ____\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;                        SPAM Classifier - Data Science\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Guilherme Tamer Lotaif\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project, is the implementation of a **Naive-Bayes Classifier** for email filtering. The goal is to create a model capable of analyzing the content of a message and calculating the conditional probabilities of it being SPAM or HAM. This will enable the automatic classification of messages, contributing to the efficiency and organization of inboxes.\n",
    "\n",
    "Bayes' theorem provides the mathematical foundation for calculating conditional probabilities, allowing us to estimate the probability of an event based on prior information. When applied to text classification, the Naive-Bayes Classifier assumes that words in a message are independent, a simplification that surprisingly proves to be effective in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries:\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 1. Import and Cleaning of Files\n",
    "\n",
    "To achieve higher performance from the prediction algorithm, we need to: remove certain characters that won't contribute to the predictions – on the contrary, not removing them hinders the classifier's effectiveness. Another cleaning method employed is the transformation of all words to lowercase, thereby eliminating the existence of the same word in different forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the file with the emails:\n",
    "df = pd.read_excel('Data/spamham2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>I notice you like looking in the shit mirror y...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Thursday night? Yeah, sure thing, we'll work i...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "2220  I notice you like looking in the shit mirror y...   ham\n",
       "898   Thursday night? Yeah, sure thing, we'll work i...   ham"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of the imported file:\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "#### Implementation of the function designed for cleaning:\n",
    "With the purpose of ensuring the integrity and coherence of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the function to remove characters that hinder the classifier:\n",
    "def Replacer (emails):\n",
    "    #Replacing each undesirable character with a space:\n",
    "    emails = emails.replace(\"*\",\"\")\n",
    "    emails = emails.replace(\"!\",\"\")\n",
    "    emails = emails.replace(\"@\",\"\")\n",
    "    emails = emails.replace(\"#\",\"\")\n",
    "    emails = emails.replace(\"$\",\"\")\n",
    "    emails = emails.replace(\"%\",\"\")\n",
    "    emails = emails.replace(\"&\",\"\")\n",
    "    emails = emails.replace(\"-\",\"\")\n",
    "    emails = emails.replace(\"_\",\"\")\n",
    "    emails = emails.replace(\"+\",\"\")\n",
    "    emails = emails.replace(\"=\",\"\")\n",
    "    emails = emails.replace(\"'\",\"\")\n",
    "    emails = emails.replace(\"?\",\"\")\n",
    "    emails = emails.replace(\";\",\"\")\n",
    "    emails = emails.replace(\",\",\"\")\n",
    "    emails = emails.replace(\".\",\"\")\n",
    "    emails = emails.replace(\":\",\"\")\n",
    "    emails = emails.replace(\")\",\"\")\n",
    "    emails = emails.replace(\"(\",\"\")\n",
    "    emails = emails.replace(\"/\",\"\")\n",
    "    emails = emails.replace('\"',\"\")\n",
    "    emails = emails.replace(\"[\",\"\")\n",
    "    emails = emails.replace(']',\"\")\n",
    "    emails = emails.replace(\"\\ \",\"\")\n",
    "    \n",
    "    #Converting all characters to lowercase:\n",
    "    emails = emails.lower()\n",
    "    #Tokenizing the words in each email:\n",
    "    emails = emails.split()\n",
    "\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Splitting the dataset into Training and Testing datasets.\n",
    "\n",
    "The dataset should be split into two parts randomly, considering:\n",
    "    \n",
    "   - 75% of the data for Training;\n",
    "   - 25% of the data for the Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning the dataframe, with 25% of the total for testing:\n",
    "train, test = train_test_split(df, test_size=0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataframe has:\n",
      " HAM: 3625 Emails\n",
      " SPAM: 554 Emails\n",
      " \n",
      "TOTAL: 4179\n"
     ]
    }
   ],
   "source": [
    "#Analyzing how many ham and spam emails exist in the training dataframe:\n",
    "ham, spam = (train[\"Class\"]).value_counts()\n",
    "total_train = train[\"Class\"].value_counts().sum()\n",
    "print(\"The training dataframe has:\\n\",\"HAM: {0} Emails\\n\".format(ham)\n",
    "                                            ,\"SPAM: {0} Emails\\n\".format(spam),\"\\nTOTAL: {0}\".format(ham+spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "#### Separating SPAM emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list for the words in SPAM emails:\n",
    "dic_SPAM = {}\n",
    "#Creating the counter variable for the total number of SPAM words:\n",
    "count_SPAM = 0\n",
    "\n",
    "#Creating a loop to assign SPAM emails to a variable:\n",
    "for email in train.Email[train.Class == \"spam\"]:\n",
    "    list_SPAM = Replacer(email)\n",
    "    #Creating a loop to allocate SPAM words in the dictionary:\n",
    "    for word in list_SPAM:\n",
    "        if word not in dic_SPAM:\n",
    "            dic_SPAM[word] = 1\n",
    "            count_SPAM += 1\n",
    "        else:\n",
    "            dic_SPAM[word] += 1\n",
    "            count_SPAM += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-repeating words: 2586 \n",
      "Total words count: 13023\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-repeating words: {0}\".format(len(dic_SPAM)),\n",
    "      \"\\nTotal words count: {0}\".format(count_SPAM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating HAM emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list for the words in HAM emails:\n",
    "dic_HAM = {}\n",
    "#Creating the counter variable for the total number of HAM words:\n",
    "count_HAM = 0\n",
    "\n",
    "#Creating a loop to assign HAM emails to a variable:\n",
    "for email in train.Email[train.Class == \"ham\"]:\n",
    "    list_HAM = Replacer(email)\n",
    "    #Creating a loop to allocate HAM words in the dictionary:\n",
    "    for word in list_HAM:\n",
    "        if word not in dic_HAM:\n",
    "            dic_HAM[word] = 1\n",
    "            count_HAM += 1\n",
    "        else:\n",
    "            dic_HAM[word] += 1\n",
    "            count_HAM += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-repeating words 6495 \n",
      "Total words count: 50679\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-repeating words {0}\".format(len(dic_HAM)),\n",
    "      \"\\nTotal words count: {0}\".format(count_HAM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to having a much larger number of HAM emails, the number of words is considerably higher, and repetition is also superior compared to SPAM emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "**Total quantity of words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 63702 Words\n"
     ]
    }
   ],
   "source": [
    "#Counting the quantity of words:\n",
    "Total_words = count_SPAM + count_HAM\n",
    "print(\"Total: {0} Words\".format(Total_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Naive-Bayes classifier\n",
    "\n",
    "The Naive-Bayes algorithm is a probabilistic classifier based on Bayes' Theorem. It utilizes the provided data to create a training and a testing partition. From the training partition, the algorithm analyzes the data, which is done independently, meaning the algorithm does not assume a dependency relationship between the factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "**Before using the classifier, let's find out some probabilities::**\n",
    "\n",
    "- The probability of a message being SPAM:<br>\n",
    "\n",
    "    $P(SPAM)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.26%\n"
     ]
    }
   ],
   "source": [
    "#Finding the probability based on the total number of SPAM emails and the overall total:\n",
    "Pspam = spam/len(train.Email)\n",
    "print(\"{:.2f}%\".format(Pspam*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The probability of a message being HAM:\n",
    "\n",
    "    $P(HAM)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.74%\n"
     ]
    }
   ],
   "source": [
    "#Finding the probability based on the total number of HAM emails and the overall total:\n",
    "Pham = ham/len(train.Email)\n",
    "print(\"{:.2f}%\".format(Pham*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The probability of a word occurring if the message in the training set is considered SPAM:\n",
    "\n",
    "    $P(Word|SPAM)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the function to find the probability of the word occurring given that the message is SPAM:\n",
    "def P_word_spam(word):\n",
    "    probability = dic_SPAM[word]/count_SPAM\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The probability of a word occurring if the message in the training set is considered HAM:\n",
    "\n",
    "    $P(Word|HAM)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the function to find the probability of the word occurring given that the message is HAM:\n",
    "def P_word_ham(word):\n",
    "    probability = dic_HAM[word]/count_HAM\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "**The classifier:** \n",
    "\n",
    "When we examine what the model uses to make its prediction, we see that it starts with the a priori information and the likelihood, which it discovers through the analysis of training data. With this, it makes its prediction.<br>\n",
    "Por exemplo:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Therefore, we can say:\n",
    "\n",
    "$$P(SPAM|message)=\\frac{P(message|SPAM)\\cdot P(SPAM)}{P(message)}$$\n",
    "<br>\n",
    "\n",
    "Hence, as we want to determine whether the email is considered SPAM or HAM, we can divide one by the other.<br>\n",
    "<br>\n",
    "\n",
    "$$\\frac {P(SPAM|message)}{P(HAM|message)}=\\frac {P(message|SPAM)\\cdot P(SPAM)}{P(message|HAM)\\cdot P(SPAM)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Implementing this model::**<br>\n",
    "\n",
    "**1)** First, we need to create a function to calculate the probability of the email being SPAM or HAM, based on the data obtained from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the function to calculate the probability of the email being SPAM or HAM:\n",
    "def Probability_calculator(dictionary, word_count, message, probability_priori):\n",
    "    clean_email = Replacer(message)\n",
    "    probability = np.log(probability_priori)\n",
    "    #Creating a loop to analyze the words in the email and how many times it appears in the dictionaries:\n",
    "    for word in clean_email:\n",
    "        Quantity = 1 #Initialize the count to 1 for Laplace smoothing\n",
    "        if word in dictionary:\n",
    "            Quantity += dictionary[word]\n",
    "            #Assigning the value of the probability of SPAM or HAM to the variable \"probability\":\n",
    "        probability += np.log(Quantity/(word_count + len(dictionary)))\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2)** Once we have the probabilities of the email being SPAM or HAM, based on the analysis of its words by the Bayesian algorithm, we need to make a comparison between the two. For this, let's create a function that, from the probabilities calculated by the previous function, returns the most likely category for the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the function to compare the probabilities of the email being SPAM or HAM and return the most likely category:\n",
    "def Probability_check(Probability_SPAM, Probability_HAM):\n",
    "    if Probability_SPAM > Probability_HAM:\n",
    "        #When the probability of being SPAM is higher, it returns SPAM:\n",
    "        return \"spam\"\n",
    "    elif Probability_SPAM < Probability_HAM:\n",
    "        #When the probability of being HAM is higher, it returns HAM:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        #When the probability of being SPAM is equal to that of being HAM, it returns \"equal\":\n",
    "        return \"=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3)** Using the functions assembled earlier to analyze and classify an email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type an email: hello friend\n"
     ]
    }
   ],
   "source": [
    "#User input to declare an email for analysis:\n",
    "message = input('Type an email: ')\n",
    "#Using the function to calculate the probability of being SPAM:\n",
    "Probability_SPAM = Probability_calculator(dic_SPAM, count_SPAM, message, Pspam)\n",
    "#Using the function to calculate the probability of being HAM:\n",
    "Probability_HAM = Probability_calculator(dic_HAM, count_HAM, message, Pham)\n",
    "#Using the function to compare the two probabilities and return the result:\n",
    "Result = Probability_check(Probability_SPAM, Probability_HAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'friend']\n",
      "\n",
      "This Email is é: HAM\n"
     ]
    }
   ],
   "source": [
    "print(Replacer(message))\n",
    "print(\"\\nThis Email is é: {0}\".format(Result.upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "**Testing the classifier:**\n",
    "\n",
    "Now that we've seen the algorithm in action, let's test it with the test set we previously separated. To do this, we'll create a new column in the dataframe with the classifier's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppressing the dataframe copy warning:\n",
    "pd.set_option('chained_assignment',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list to store the results of the Naive Bayes classifier:\n",
    "results_column = []\n",
    "#Creating a loop to check the emails in the test set:\n",
    "for test_message in test[\"Class\"]:\n",
    "    #Using the function to calculate the probability of being SPAM:\n",
    "    SPAM_probability_test = Probability_calculator(dic_SPAM, count_SPAM, test_message, Pspam)\n",
    "    #Using the function to calculate the probability of being HAM:\n",
    "    HAM_probability_test = Probability_calculator(dic_HAM, count_HAM, test_message, Pham)\n",
    "    #Adding the algorithm results to the list:\n",
    "    results_column.append(Probability_check(SPAM_probability_test, HAM_probability_test))\n",
    "#Assigning all the results to a new column in the test dataframe:\n",
    "test['Expected'] = results_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Life is more strict than teacher... Bcoz Teach...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Nah dub but je still buff</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class Expected\n",
       "228   Life is more strict than teacher... Bcoz Teach...   ham      ham\n",
       "1673                          Nah dub but je still buff   ham      ham"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has:\n",
      " - HAM: 1200 Emails\n",
      " - SPAM: 193 Emails\n",
      " \n",
      "TOTAL: 1393\n",
      "\n",
      "The algorithm returns:\n",
      " - HAM: 1200 Emails\n",
      " - SPAM 193 Emails\n",
      " \n",
      "TOTAL: 1393\n"
     ]
    }
   ],
   "source": [
    "#Analyzing how many ham and spam emails exist in the test dataframe:\n",
    "ham_test, spam_test = (test[\"Class\"]).value_counts()\n",
    "train_total = test[\"Class\"].value_counts().sum()\n",
    "\n",
    "#Finding out the test items:\n",
    "expected_counts = test[\"Expected\"].value_counts()\n",
    "\n",
    "#Acquiring the value counts:\n",
    "ham_expected = expected_counts.get(\"ham\", 0)\n",
    "spam_expected = expected_counts.get(\"spam\", 0)\n",
    "\n",
    "print(\"The dataframe has:\\n\",\"- HAM: {0} Emails\\n\".format(ham_test)\n",
    "     ,\"- SPAM: {0} Emails\\n\".format(spam_test),\"\\nTOTAL: {0}\".format(ham_test+spam_test))\n",
    "\n",
    "print(\"\\nThe algorithm returns:\\n - HAM: {0} Emails\\n\".format(ham_expected)\n",
    "     ,\"- SPAM {0} Emails\\n\".format(spam_expected),\"\\nTOTAL: {0}\".format(ham_expected+spam_expected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on numerous code executions, it is observed that in cases where the result is incorrect, it is because the code considers all emails as HAM. In the event of such occurrence, it is recommended to rerun the code and compare the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "**Evaluation of successes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating counters for the classifier:\n",
    "false_positives, true_positives, false_negatives, true_negatives = 0,0,0,0\n",
    "\n",
    "#Creating a loop to compare the classifier results with the pre-defined classification:\n",
    "for Class_test, Expected_test in zip(test[\"Class\"], test[\"Expected\"]):\n",
    "    if Class_test == \"spam\" and Expected_test == \"spam\":\n",
    "        true_positives += 1\n",
    "    elif Class_test == \"ham\" and Expected_test == \"spam\":\n",
    "        false_positives += 1\n",
    "    elif Class_test == \"spam\" and Expected_test == \"ham\":\n",
    "        false_negatives += 1\n",
    "    else:\n",
    "        true_negatives += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **%** False positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n"
     ]
    }
   ],
   "source": [
    "#When the classifier claims to be SPAM but should be HAM:\n",
    "print(\"{:.2f}%\".format((false_positives/len(test))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **%** True positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.85%\n"
     ]
    }
   ],
   "source": [
    "#When the classifier correctly claims to be SPAM:\n",
    "print(\"{:.2f}%\".format((true_positives/len(test))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **%** False negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n"
     ]
    }
   ],
   "source": [
    "#When the classifier claims to be HAM but should be SPAM:\n",
    "print(\"{:.2f}%\".format((false_negatives/len(test))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **%** True negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.15%\n"
     ]
    }
   ],
   "source": [
    "#When the classifier correctly claims to be HAM:\n",
    "print(\"{:.2f}%\".format(((true_negatives/len(test))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Is the accuracy acceptable?**<br>\n",
    "To evaluate the accuracy of the algorithm, we will analyze the number of correct predictions made by our classifier and divide it by the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a variable to sum the quantity of correct predictions:\n",
    "correct = 0\n",
    "#Creating a loop to compare the prediction with the existing classification:\n",
    "for result_class, result_expected in zip(test[\"Class\"],test[\"Expected\"]):\n",
    "    if result_class == result_expected:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(100*correct/len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier fitness:\n",
    "\n",
    "The code written for the Naive Bayes classifier algorithm appears to be working successfully. When tested with the test set, we can see from the dataframe that the predictions are indeed matching in the majority of cases. However, with the change in the test set each time we run the code, its accuracy varies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Classifier performance with training set alterations<br>\n",
    "This phase is being conducted with the purpose of investigating whether a modification in the training set influences the quality of the classifier. In this context, we are reproducing the same steps already executed so far, repeating the process iteratively for 10,000 times. The goal is to obtain a substantial amount of information to conclude if there is indeed any significant change resulting from this modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to store accuracy rates each time the training and test sets are swapped:\n",
    "Accuracy_List = []\n",
    "\n",
    "# Creating a loop to run all necessary steps for the classifier to function 10,000 times:\n",
    "for iteration in range(10000):\n",
    "    # Splitting the dataframe, with 25% of the total for testing:\n",
    "    training_data, test_data = train_test_split(df, test_size=0.25)\n",
    "\n",
    "    # Analyzing the number of ham and spam emails in the training dataframe:\n",
    "    ham_count, spam_count = (training_data[\"Class\"]).value_counts()\n",
    "\n",
    "    # Creating a list for the words in spam emails:\n",
    "    dic_SPAM = {}\n",
    "    # Creating a counter variable for the total number of spam words:\n",
    "    spam_word_count = 0\n",
    "\n",
    "    # Creating a loop to assign spam emails to a variable:\n",
    "    for email_training in training_data.Email[training_data.Class == \"spam\"]:\n",
    "        spam_list = Replacer(email_training)\n",
    "\n",
    "        # Creating a loop to allocate spam words in the dictionary:\n",
    "        for word in spam_list:\n",
    "            if word not in dic_SPAM:\n",
    "                dic_SPAM[word] = 1\n",
    "                spam_word_count += 1\n",
    "            else:\n",
    "                dic_SPAM[word] += 1\n",
    "                spam_word_count += 1\n",
    "\n",
    "    # Creating a list for the words in ham emails:\n",
    "    dic_HAM = {}\n",
    "    # Creating a counter variable for the total number of ham words:\n",
    "    ham_word_count = 0\n",
    "\n",
    "    # Creating a loop to assign ham emails to a variable:\n",
    "    for email_training in training_data.Email[training_data.Class == \"ham\"]:\n",
    "        ham_list = Replacer(email_training)\n",
    "\n",
    "        # Creating a loop to allocate ham words in the dictionary:\n",
    "        for word in ham_list:\n",
    "            if word not in dic_HAM:\n",
    "                dic_HAM[word] = 1\n",
    "                ham_word_count += 1\n",
    "            else:\n",
    "                dic_HAM[word] += 1\n",
    "                ham_word_count += 1\n",
    "\n",
    "    # Calculating the probability based on the total number of spam emails and the overall total:\n",
    "    Pspam = spam_count / len(training_data.Email)\n",
    "\n",
    "    # Calculating the probability based on the total number of ham emails and the overall total:\n",
    "    Pham = ham_count / len(training_data.Email)\n",
    "\n",
    "    # Creating a list to store the results of the Naive Bayes classifier:\n",
    "    Result_Column = []\n",
    "\n",
    "    # Creating a loop to check the email from the test set:\n",
    "    for message in test_data[\"Class\"]:\n",
    "        # Using the function to calculate the probability of being spam:\n",
    "        Probability_SPAM = Probability_calculator(dic_SPAM, spam_word_count, message, Pspam)\n",
    "        # Using the function to calculate the probability of being ham:\n",
    "        Probability_HAM = Probability_calculator(dic_HAM, ham_word_count, message, Pham)\n",
    "        # Adding the results of the algorithm to the list:\n",
    "        Result_Column.append(Probability_check(Probability_SPAM, Probability_HAM))\n",
    "\n",
    "    # Assigning all results to a new column in the test dataframe:\n",
    "    test_data['Expected'] = Result_Column\n",
    "\n",
    "    # Creating counters for the quantities of classifier accuracies:\n",
    "    True_Positives, True_Negatives = 0, 0\n",
    "\n",
    "    # Creating a loop to compare the results of the classifier with the predefined classification:\n",
    "    for Class_test, Expected_test in zip(test_data[\"Class\"], test_data[\"Expected\"]):\n",
    "        if Class_test == \"spam\" and Expected_test == \"spam\":\n",
    "            True_Positives += 1\n",
    "        elif Class_test == \"ham\" and Expected_test == \"ham\":\n",
    "            True_Negatives += 1\n",
    "\n",
    "    # Allocating the accuracy rate of the classifier each time the loop runs:\n",
    "    Accuracy_List.append((100 * (True_Positives + True_Negatives)) / len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "### 4.1 Analise dos resultados:\n",
    "\n",
    "Dado que o código anterior executa o classificador em 10.000 conjuntos de dados distintos, esta seção é dedicada a uma análise de sua eficácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for values different from 100%:\n",
    "list_1 = []\n",
    "\n",
    "# Creating a loop to assign values different from 100% to the list:\n",
    "for index in range(len(Accuracy_List)):\n",
    "    if Accuracy_List[index] != 100:\n",
    "        list_1.append(Accuracy_List[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of times the classifier is less than 100% accurate:\n",
      "- 25.58%\n"
     ]
    }
   ],
   "source": [
    "# Creating a counter for 100% accuracy:\n",
    "count_100 = 0\n",
    "# Creating a counter for other accuracy values:\n",
    "count_other = 0\n",
    "# Loop to perform the counting:\n",
    "for accuracy in Accuracy_List:\n",
    "    if accuracy == 100:\n",
    "        count_100 += 1\n",
    "    else:\n",
    "        count_other += 1\n",
    "# Calculating the percentage of times when it's not 100% accuracy:\n",
    "percentage_other = (count_other / (count_100 + count_other)) * 100\n",
    "print(\"Percentage of times the classifier is less than 100% accurate:\\n- {:.2f}%\".format(percentage_other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Generating the histogram of the frequency distribution when 100% is not achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the histogram of the accuracy percentage of the classifiers:\n",
    "plt.hist(list_1, bins=200, density=True)\n",
    "plt.title(\"\\nFrequency Distribution when 100% Accuracy is Not Achieved\")\n",
    "plt.xlabel(\"Percentage\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the classifier 10,000 times, notable results stand out, indicating a remarkable effectiveness of the model, achieving 100% accuracy in approximately 75% of instances. Furthermore, in cases where accuracy does not reach the maximum, there is a consistent pattern around 86/87%.\n",
    "\n",
    "By focusing on the variability in results, an influence of the modification in the training set on the classifier's performance becomes evident. This observation reinforces the importance of the selection and quality of training data, highlighting its crucial role in the predictive capacity of the model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
